<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Exploratory Findings - Markdown API (MAPI)</title>
    <link rel="icon" type="image/svg+xml" href="favicon.svg">

    <!-- Open Graph / Social Media -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://markdownapi.org/findings.html">
    <meta property="og:title" content="MAPI vs OpenAPI: End-to-End Test Results">
    <meta property="og:description" content="Exploratory findings from end-to-end testing of OpenAPI vs MAPI vs MAPI Skills with real API execution across 3 production APIs.">
    <meta property="og:image" content="https://markdownapi.org/social-preview.png">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:url" content="https://markdownapi.org/findings.html">
    <meta name="twitter:title" content="MAPI vs OpenAPI: End-to-End Test Results">
    <meta name="twitter:description" content="Exploratory findings from end-to-end testing of OpenAPI vs MAPI vs MAPI Skills with real API execution across 3 production APIs.">
    <meta name="twitter:image" content="https://markdownapi.org/social-preview.png">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@400;500;600;700&family=Source+Serif+4:ital,wght@0,400;0,600;1,400&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
    <style>
        :root {
            --mustard: #D4A03E;
            --burnt-orange: #C85D3E;
            --teal: #2A7B7B;
            --olive: #5E7153;
            --cream: #FAF7F2;
            --warm-white: #FFFEF9;
            --charcoal: #2D2D2D;
            --light-charcoal: #4A4A4A;
            --sand: #E8E0D5;
            --green: #4A7C59;
            --red: #C85D5D;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { font-family: 'Space Grotesk', sans-serif; background-color: var(--cream); color: var(--charcoal); line-height: 1.7; }

        .container { max-width: 900px; margin: 0 auto; padding: 0 2rem; }
        .container-wide { max-width: 1100px; margin: 0 auto; padding: 0 2rem; }

        /* Header */
        header { padding: 1.5rem 0; }
        header .container-wide { display: flex; align-items: center; justify-content: space-between; }
        .logo { font-size: 1.25rem; font-weight: 600; color: var(--teal); text-decoration: none; display: flex; align-items: center; gap: 0.5rem; }
        .logo-mark { width: 32px; height: 32px; background: var(--burnt-orange); border-radius: 6px; display: flex; align-items: center; justify-content: center; color: white; font-weight: 700; font-size: 0.9rem; }
        .main-nav { display: flex; align-items: center; gap: 2rem; }
        .main-nav a { text-decoration: none; color: var(--light-charcoal); font-size: 0.95rem; font-weight: 500; transition: color 0.2s ease; }
        .main-nav a:hover, .main-nav a.active { color: var(--teal); }
        .main-nav a.nav-cta { background: var(--teal); color: white; padding: 0.6rem 1.25rem; border-radius: 8px; }
        .main-nav a.nav-cta:hover { background: #237070; color: white; }
        .main-nav a.nav-cta-alt { background: var(--burnt-orange); }
        .main-nav a.nav-cta-alt:hover { background: #A84D32; }

        /* Mobile Navigation */
        .mobile-menu-btn { display: none; background: none; border: none; cursor: pointer; padding: 0.5rem; z-index: 200; }
        .mobile-menu-btn span { display: block; width: 24px; height: 2px; background: var(--charcoal); margin: 5px 0; transition: all 0.3s ease; }
        .mobile-menu-btn.active span:nth-child(1) { transform: rotate(45deg) translate(5px, 5px); }
        .mobile-menu-btn.active span:nth-child(2) { opacity: 0; }
        .mobile-menu-btn.active span:nth-child(3) { transform: rotate(-45deg) translate(5px, -5px); }
        .mobile-menu { display: none; position: fixed; top: 0; left: 0; right: 0; bottom: 0; background: var(--charcoal); z-index: 150; flex-direction: column; justify-content: center; align-items: center; gap: 2rem; }
        .mobile-menu.active { display: flex; }
        .mobile-menu a { color: var(--cream); text-decoration: none; font-size: 1.5rem; font-weight: 600; padding: 1rem 2rem; min-height: 48px; display: flex; align-items: center; }
        .mobile-menu a:hover { color: var(--mustard); }
        .mobile-menu a.nav-cta { background: var(--teal); border-radius: 8px; font-size: 1.25rem; }
        .mobile-menu a.nav-cta-alt { background: var(--burnt-orange); }

        /* Page Header */
        .page-header { padding: 3rem 0 2rem; border-bottom: 1px solid var(--sand); }
        .page-header h1 { font-family: 'Source Serif 4', Georgia, serif; font-size: 2.75rem; font-weight: 600; color: var(--charcoal); margin-bottom: 0.75rem; }
        .page-header .subtitle { font-size: 1.15rem; color: var(--light-charcoal); max-width: 700px; line-height: 1.7; }
        .page-header .meta { font-size: 0.9rem; color: var(--light-charcoal); margin-top: 1rem; }
        .page-header .meta time { font-weight: 500; }

        /* Content */
        .content { padding: 3rem 0 4rem; }
        .content h2 { font-family: 'Source Serif 4', Georgia, serif; font-size: 1.75rem; font-weight: 600; color: var(--charcoal); margin: 3rem 0 1rem; padding-top: 1rem; border-top: 1px solid var(--sand); }
        .content h2:first-child { margin-top: 0; padding-top: 0; border-top: none; }
        .content h3 { font-size: 1.2rem; font-weight: 600; color: var(--charcoal); margin: 2rem 0 0.75rem; }
        .content p { font-size: 1.05rem; color: var(--light-charcoal); margin-bottom: 1.25rem; }
        .content ul, .content ol { margin: 0 0 1.5rem 1.5rem; color: var(--light-charcoal); }
        .content li { font-size: 1.05rem; margin-bottom: 0.5rem; }
        .content strong { color: var(--charcoal); font-weight: 600; }
        .content code { background: var(--sand); padding: 0.15rem 0.4rem; border-radius: 4px; font-family: 'JetBrains Mono', monospace; font-size: 0.9em; color: var(--burnt-orange); }

        /* Key Findings Box */
        .key-findings { background: linear-gradient(135deg, var(--teal) 0%, #1E5F5F 100%); border-radius: 16px; padding: 2rem; margin: 2rem 0; color: white; }
        .key-findings h3 { color: white; margin-top: 0; margin-bottom: 1rem; font-size: 1.1rem; text-transform: uppercase; letter-spacing: 1px; opacity: 0.9; }
        .key-findings ul { margin: 0; list-style: none; padding: 0; }
        .key-findings li { font-size: 1.1rem; margin-bottom: 0.75rem; padding-left: 1.5rem; position: relative; color: rgba(255,255,255,0.95); }
        .key-findings li::before { content: "→"; position: absolute; left: 0; color: var(--mustard); font-weight: 600; }

        /* Tables */
        .data-table { width: 100%; border-collapse: collapse; margin: 1.5rem 0 2rem; font-size: 0.95rem; background: var(--warm-white); border-radius: 12px; overflow: hidden; box-shadow: 0 2px 8px rgba(0,0,0,0.04); }
        .data-table th { background: var(--charcoal); color: white; font-weight: 600; text-align: left; padding: 1rem 1.25rem; font-size: 0.85rem; text-transform: uppercase; letter-spacing: 0.5px; }
        .data-table td { padding: 1rem 1.25rem; border-bottom: 1px solid var(--sand); color: var(--light-charcoal); }
        .data-table tr:last-child td { border-bottom: none; }
        .data-table tr:hover td { background: rgba(42, 123, 123, 0.04); }
        .data-table .num { font-family: 'JetBrains Mono', monospace; font-size: 0.9rem; }
        .data-table .winner { background: rgba(74, 124, 89, 0.1); font-weight: 600; color: var(--green); }
        .data-table .na { color: var(--light-charcoal); opacity: 0.5; font-style: italic; }
        .data-table .api-name { font-weight: 600; color: var(--charcoal); }

        /* Comparison Cards */
        .comparison-grid { display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin: 2rem 0; }
        .comparison-card { background: var(--warm-white); border-radius: 12px; padding: 1.5rem; border: 2px solid var(--sand); }
        .comparison-card.openapi { border-color: var(--burnt-orange); }
        .comparison-card.mapi { border-color: var(--teal); }
        .comparison-card h4 { font-size: 1rem; margin-bottom: 1rem; }
        .comparison-card.openapi h4 { color: var(--burnt-orange); }
        .comparison-card.mapi h4 { color: var(--teal); }
        .stat { display: flex; justify-content: space-between; padding: 0.5rem 0; border-bottom: 1px solid var(--sand); }
        .stat:last-child { border-bottom: none; }
        .stat-label { color: var(--light-charcoal); font-size: 0.9rem; }
        .stat-value { font-family: 'JetBrains Mono', monospace; font-weight: 600; color: var(--charcoal); }

        /* Callout */
        .callout { background: var(--warm-white); border-left: 4px solid var(--mustard); border-radius: 0 12px 12px 0; padding: 1.25rem 1.5rem; margin: 1.5rem 0; }
        .callout.info { border-left-color: var(--teal); }
        .callout.warning { border-left-color: var(--burnt-orange); }
        .callout-title { font-weight: 600; font-size: 0.9rem; margin-bottom: 0.5rem; color: var(--charcoal); }
        .callout p { margin-bottom: 0; font-size: 0.95rem; }

        /* Code Block */
        .code-block { background: var(--charcoal); border-radius: 12px; padding: 1.5rem; margin: 1.5rem 0; overflow-x: auto; }
        .code-block pre { margin: 0; font-family: 'JetBrains Mono', monospace; font-size: 0.85rem; line-height: 1.6; color: #E8E0D5; }
        .code-block .comment { color: #6A9955; }

        /* Responsive */
        @media (max-width: 768px) {
            .comparison-grid { grid-template-columns: 1fr; }
            .data-table { font-size: 0.85rem; }
            .data-table th, .data-table td { padding: 0.75rem; }
        }
        @media (max-width: 600px) {
            .mobile-menu-btn { display: block; }
            .main-nav { display: none; }
            .page-header h1 { font-size: 2rem; }
            .key-findings { padding: 1.5rem; }
            .key-findings li { font-size: 1rem; }
        }

        /* Footer */
        .site-footer { background: var(--charcoal); color: var(--cream); text-align: center; padding: 2rem; margin-top: 3rem; }
        .site-footer a { color: var(--mustard); text-decoration: none; }
        .site-footer a:hover { text-decoration: underline; }
        .footer-divider { color: rgba(255,255,255,0.3); margin: 0 1rem; }
    </style>
</head>
<body>
    <header>
        <div class="container-wide">
            <a href="index.html" class="logo"><div class="logo-mark">M</div>MarkdownAPI</a>
            <nav class="main-nav">
                <a href="getting-started.html">Getting Started</a>
                <a href="skills.html">Skills</a>
                <a href="converter.html">Converter</a>
                <a href="findings.html" class="active">Findings</a>
                <a href="get-involved.html">Get Involved</a>
                <a href="specs/mapi-specification-v0.94.html" class="nav-cta">Read Spec</a>
            </nav>
            <button class="mobile-menu-btn" onclick="toggleMobileMenu()" aria-label="Toggle menu">
                <span></span><span></span><span></span>
            </button>
        </div>
    </header>
    <div class="mobile-menu" id="mobileMenu">
        <a href="index.html">Home</a>
        <a href="getting-started.html">Getting Started</a>
        <a href="skills.html">Skills</a>
        <a href="converter.html">Converter</a>
        <a href="findings.html">Findings</a>
        <a href="get-involved.html">Get Involved</a>
        <a href="specs/mapi-specification-v0.94.html" class="nav-cta">Read Spec</a>
    </div>

    <main>
        <section class="page-header">
            <div class="container">
                <h1>Exploratory Findings</h1>
                <p class="subtitle">End-to-end testing of OpenAPI vs MAPI vs MAPI Skills with real API execution across three production APIs.</p>
                <p class="meta">Last updated: <time datetime="2026-01-20">January 20, 2026</time> · 10 E2E test cases · Claude Haiku 4.5</p>
            </div>
        </section>

        <section class="content">
            <div class="container">

                <div class="callout warning">
                    <div class="callout-title">Exploratory Results</div>
                    <p>These are early exploratory findings from a small test set (10 tests across 3 APIs). Results should be interpreted directionally, not as statistically significant. We're sharing them for transparency as we continue to expand the test suite.</p>
                </div>

                <div class="key-findings">
                    <h3>Key Observations</h3>
                    <ul>
                        <li>MAPI and MAPI Skills both achieved <strong>100% API success rate</strong> across all tests</li>
                        <li>MAPI Skills uses only <strong>9.3% of OpenAPI's tokens</strong> (90.7% reduction)</li>
                        <li>Both MAPI formats achieved <strong>100% capability matching accuracy</strong></li>
                        <li>These tests execute <strong>real API calls</strong>—not just LLM comprehension checks</li>
                        <li>OpenAPI GitHub tests were rate-limited due to large spec size (~108K tokens per request)</li>
                    </ul>
                </div>

                <h2>Methodology</h2>

                <p>We built an end-to-end test harness that goes beyond LLM comprehension testing. Each test executes the <strong>full agent workflow</strong>: understanding a natural language request, constructing an HTTP request, and executing it against a live API. This measures real-world usability, not just spec readability.</p>

                <h3>Test Design</h3>

                <p>Each test case consists of:</p>
                <ul>
                    <li>A natural language request (e.g., "Count how many tokens are in 'Hello, world!'")</li>
                    <li>An expected capability (e.g., <code>messages.count_tokens</code>)</li>
                    <li>A response validator that checks the actual API response</li>
                </ul>

                <p>The test compares three specification formats: OpenAPI, MAPI (full spec), and MAPI Skills (progressive loading). For each format, we measure:</p>
                <ul>
                    <li><strong>API Success Rate</strong> — did the constructed request return a valid response?</li>
                    <li><strong>Capability Accuracy</strong> — did the LLM identify the correct capability?</li>
                    <li><strong>Token Usage</strong> — total input + output tokens consumed</li>
                    <li><strong>Latency</strong> — end-to-end time including API execution</li>
                </ul>

                <h3>E2E Test Flow</h3>

                <p>Each test follows this flow:</p>
                <ol>
                    <li><strong>Phase 1: Intent Matching</strong> — LLM identifies which capability handles the request</li>
                    <li><strong>Phase 2: Request Construction</strong> — LLM builds the HTTP request (method, path, body)</li>
                    <li><strong>Phase 3: API Execution</strong> — Request is sent to the live API</li>
                    <li><strong>Phase 4: Response Validation</strong> — Response is checked against expected structure</li>
                </ol>

                <div class="callout info">
                    <div class="callout-title">Why E2E Testing Matters</div>
                    <p>Comprehension-only tests ("can the LLM pick the right capability?") don't prove an agent can actually use the API. E2E tests verify the full chain: understanding → construction → execution → validation.</p>
                </div>

                <h3>Test Infrastructure</h3>

                <ul>
                    <li><strong>Model:</strong> Claude Haiku 4.5 (claude-haiku-4-5-20251001)</li>
                    <li><strong>Test harness:</strong> TypeScript/Node.js</li>
                    <li><strong>Rate limit handling:</strong> Exponential backoff with up to 5 retries; rate-limited tests are skipped, not failed</li>
                    <li><strong>Test scope:</strong> Read-only operations only (no mutations)</li>
                </ul>

                <h2>APIs Tested</h2>

                <table class="data-table">
                    <thead>
                        <tr>
                            <th>API</th>
                            <th>E2E Tests</th>
                            <th>Test Types</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="api-name">Anthropic Messages</td>
                            <td class="num">3</td>
                            <td>Token counting, message creation</td>
                        </tr>
                        <tr>
                            <td class="api-name">GitHub REST</td>
                            <td class="num">4</td>
                            <td>Repository info, issues, pull requests</td>
                        </tr>
                        <tr>
                            <td class="api-name">Google Cloud Billing</td>
                            <td class="num">3</td>
                            <td>Billing accounts, services listing</td>
                        </tr>
                    </tbody>
                </table>

                <h2>Results by API</h2>

                <h3>Anthropic Messages API</h3>
                <p>Tests: Token counting, message creation with Claude.</p>

                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>OpenAPI</th>
                            <th>MAPI</th>
                            <th>Skill</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>API Success</td>
                            <td class="num">67% (2/3)</td>
                            <td class="num winner">100% (3/3)</td>
                            <td class="num winner">100% (3/3)</td>
                        </tr>
                        <tr>
                            <td>Capability Accuracy</td>
                            <td class="num">67%</td>
                            <td class="num winner">100%</td>
                            <td class="num winner">100%</td>
                        </tr>
                    </tbody>
                </table>

                <p><strong>Observation:</strong> OpenAPI failed one test because the LLM selected a model name (<code>claude-3-5-sonnet-2024</code>) that doesn't exist in the API. MAPI and Skill specs include explicit model name guidance, avoiding this error.</p>

                <h3>GitHub REST API</h3>
                <p>Tests: Repository details, listing issues, listing pull requests.</p>

                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>OpenAPI</th>
                            <th>MAPI</th>
                            <th>Skill</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>API Success</td>
                            <td class="na">N/A (rate limited)</td>
                            <td class="num winner">100% (4/4)</td>
                            <td class="num winner">100% (4/4)</td>
                        </tr>
                        <tr>
                            <td>Capability Accuracy</td>
                            <td class="na">N/A</td>
                            <td class="num winner">100%</td>
                            <td class="num winner">100%</td>
                        </tr>
                    </tbody>
                </table>

                <p><strong>Observation:</strong> All 4 OpenAPI tests hit rate limits and were skipped. The large OpenAPI spec (~108K tokens per request) consumes rate limit budget faster than MAPI (~10K tokens) or Skill (~1K tokens). This demonstrates a practical limitation of large specs.</p>

                <h3>Google Cloud Billing API</h3>
                <p>Tests: Listing billing accounts, account details, listing services.</p>

                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>OpenAPI</th>
                            <th>MAPI</th>
                            <th>Skill</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>API Success</td>
                            <td class="num winner">100% (3/3)</td>
                            <td class="num winner">100% (3/3)</td>
                            <td class="num winner">100% (3/3)</td>
                        </tr>
                        <tr>
                            <td>Capability Accuracy</td>
                            <td class="num">100%</td>
                            <td class="num winner">100%</td>
                            <td class="num winner">100%</td>
                        </tr>
                    </tbody>
                </table>

                <p><strong>Observation:</strong> All three formats achieved 100% success on GCP Billing tests. OpenAPI performed well here because the spec is moderate in size.</p>

                <h2>Summary</h2>

                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>OpenAPI</th>
                            <th>MAPI</th>
                            <th>Skill</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>API Success Rate</td>
                            <td class="num">83% (5/6)*</td>
                            <td class="num winner">100% (10/10)</td>
                            <td class="num winner">100% (10/10)</td>
                        </tr>
                        <tr>
                            <td>Capability Accuracy</td>
                            <td class="num">50%</td>
                            <td class="num winner">100%</td>
                            <td class="num winner">100%</td>
                        </tr>
                        <tr>
                            <td>Total Tokens</td>
                            <td class="num">108,530</td>
                            <td class="num">102,851</td>
                            <td class="num winner">10,065</td>
                        </tr>
                        <tr>
                            <td>% of OpenAPI Tokens</td>
                            <td class="num">100%</td>
                            <td class="num">94.8%</td>
                            <td class="num winner">9.3%</td>
                        </tr>
                        <tr>
                            <td>Avg Latency</td>
                            <td class="num">2,020ms</td>
                            <td class="num">1,890ms</td>
                            <td class="num winner">1,710ms</td>
                        </tr>
                    </tbody>
                </table>

                <p><em>* OpenAPI ran 6 of 10 tests; 4 GitHub tests were skipped due to rate limits (not counted as failures).</em></p>

                <h2>MAPI Skills: Progressive Loading</h2>

                <p>MAPI Skills uses a 2-phase approach that dramatically reduces token usage:</p>

                <ol>
                    <li><strong>Phase 1:</strong> Load the lightweight Skill.md index (~1-3KB) with capability IDs and intent keywords</li>
                    <li><strong>Phase 2:</strong> Match intent to capability, then load only the required capability file (~1KB)</li>
                </ol>

                <h3>Token Efficiency Results</h3>

                <table class="data-table">
                    <thead>
                        <tr>
                            <th>Format</th>
                            <th>Total Tokens</th>
                            <th>% of OpenAPI</th>
                            <th>Reduction</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td class="api-name">OpenAPI</td>
                            <td class="num">108,530</td>
                            <td class="num">100%</td>
                            <td class="num">—</td>
                        </tr>
                        <tr>
                            <td class="api-name">MAPI (Full)</td>
                            <td class="num">102,851</td>
                            <td class="num">94.8%</td>
                            <td class="num">5.2%</td>
                        </tr>
                        <tr>
                            <td class="api-name">MAPI Skill</td>
                            <td class="num winner">10,065</td>
                            <td class="num winner">9.3%</td>
                            <td class="num winner">90.7%</td>
                        </tr>
                    </tbody>
                </table>

                <p><strong>Observation:</strong> MAPI Skills achieved <strong>90.7% token reduction</strong> compared to OpenAPI while maintaining 100% accuracy across all E2E tests. The progressive loading approach loads only what's needed for each request.</p>

                <div class="callout info">
                    <div class="callout-title">When to Use Skills</div>
                    <p>MAPI Skills is optimal for APIs where token efficiency matters—especially when running many requests or working within rate limits. The 10x token reduction means 10x more API calls within the same budget.</p>
                </div>

                <h2>Challenges Encountered</h2>

                <h3>1. Rate Limiting with Large Specs</h3>
                <p>OpenAPI's large spec sizes (~108K tokens for GitHub) consume rate limit budgets quickly. All 4 GitHub OpenAPI tests hit rate limits and were skipped, while MAPI and Skill completed successfully. This is a real-world limitation of large specifications.</p>

                <h3>2. Model Name Hallucination</h3>
                <p>OpenAPI tests failed when the LLM invented model names not in the actual API (e.g., <code>claude-3-5-sonnet-2024</code>). MAPI specs with explicit model guidance avoided this issue.</p>

                <h3>3. Asymmetric Test Coverage</h3>
                <p>Rate limiting caused OpenAPI to run fewer tests (6/10) than MAPI and Skill (10/10). This makes direct comparison difficult—OpenAPI's "83% success" is from a smaller, potentially easier subset.</p>

                <h3>4. LLM Variance</h3>
                <p>Results vary between runs due to LLM non-determinism. A test that passes in one run may fail in another. These results represent a single run and should be interpreted directionally.</p>

                <h2>Limitations</h2>

                <ul>
                    <li><strong>Small sample size:</strong> Only 10 tests across 3 APIs—results are directional, not statistically significant</li>
                    <li><strong>Single run:</strong> No averaging across multiple runs to account for LLM variance</li>
                    <li><strong>Asymmetric coverage:</strong> OpenAPI completed 6/10 tests; MAPI/Skill completed 10/10</li>
                    <li><strong>Single model tested:</strong> Results are specific to Claude Haiku 4.5; other models may differ</li>
                    <li><strong>Read-only tests only:</strong> No mutation operations tested (creates, updates, deletes)</li>
                    <li><strong>Hand-written specs:</strong> MAPI/Skill specs were written for this test; quality may vary</li>
                </ul>

                <h2>Reproducing These Results</h2>

                <p>The E2E test harness and all specifications are available in the MAPI repository:</p>

                <div class="code-block">
                    <pre><span class="comment"># Clone the repository</span>
git clone https://github.com/jeffrschneider/markdownapi.git
cd markdownapi/tests/harness

<span class="comment"># Install dependencies</span>
npm install

<span class="comment"># Set your API keys in .env.local (project root)</span>
ANTHROPIC_API_KEY=your-anthropic-key
GITHUB_TOKEN=your-github-token
GOOGLE_APPLICATION_CREDENTIALS=/path/to/gcp-credentials.json

<span class="comment"># Build and run E2E tests</span>
npm run build
node dist/e2e-runner.js</pre>
                </div>

                <div class="callout warning">
                    <div class="callout-title">Rate Limits</div>
                    <p>OpenAPI tests may hit rate limits due to large spec sizes. The test harness implements exponential backoff and skips rate-limited tests rather than failing them.</p>
                </div>

            </div>
        </section>
    </main>

    <footer class="site-footer">
        <p>&copy; 2026 MAPI Project <span class="footer-divider">|</span> <a href="authors.html">The Authors</a></p>
    </footer>

    <script>
        function toggleMobileMenu() {
            document.getElementById('mobileMenu').classList.toggle('active');
            document.querySelector('.mobile-menu-btn').classList.toggle('active');
        }
    </script>
</body>
</html>
